{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **HOTEL BOOKING CANCELLATION PREDICTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hotel booking](../images/image-hotel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Read and Pre-Clean the Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module for load and pre cleaning of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modularizando la carga de datos y limpieza inicial\n",
    "def inicial_clean(df):\n",
    "    # Remove columns with personal information about customers\n",
    "    df.drop(['name', 'email', 'phone-number', 'credit_card'], axis=1, inplace=True)\n",
    "    # Remove data leakeage\n",
    "    df.drop(['reservation_status', 'reservation_status_date'], axis=1, inplace=True)\n",
    "    # Convert objects to strings\n",
    "    obj_columns = df.select_dtypes('object').columns\n",
    "    df[obj_columns] = df[obj_columns].astype(str)\n",
    "    return df\n",
    "\n",
    "def load_data(file_path):\n",
    "    # Load the dataset\n",
    "    df_hotel_bookings_raw = pd.read_csv(file_path)\n",
    "    # Inicial clean (drop unnecessary columns and correct the data type)\n",
    "    df_hotel_bookings = inicial_clean(df_hotel_bookings_raw)\n",
    "    return df_hotel_bookings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"../data/dataset.csv\"\n",
    "# df_hotel_booking = load_data(file_path)\n",
    "# df_hotel_booking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_hotel_booking.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Split the Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the size of the datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(df, target:str, train_size=0.8, val_test_proportion=0.5):\n",
    "    \n",
    "    original_size = df.shape[0]\n",
    "\n",
    "    X = df.drop([target], axis=1).copy() # indenpendent variables\n",
    "    y = df[target].copy() # denpendent (target)\n",
    "\n",
    "    X_train, X_rest, y_train, y_rest = train_test_split(X, y, train_size=train_size)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_rest, y_rest, train_size=val_test_proportion)\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # Save the size of the datasets using \"mlflow\"\n",
    "    # --------------------------------------------\n",
    "    mlflow.log_params({\n",
    "        'dataset_size': original_size,\n",
    "        'training_set_size': len(X_train),\n",
    "        'validate_set_size': len(X_val),\n",
    "        'test_set_size': len(X_test),\n",
    "    })\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train, X_test, y_test, X_val, y_val = split_data(df_hotel_booking, 'is_canceled', train_size=0.8, val_test_proportion=0.5)\n",
    "# print(\"X_train, X_test, X_val\")\n",
    "# print(X_train.shape, X_test.shape, X_val.shape)\n",
    "# print(len(X_train), len(X_test), len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pipeline for Pre Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the preprocessing using mlflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, Binarizer, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "\n",
    "def build_pipeline():\n",
    "    \n",
    "    # -----------------------------------------------------------------------------------------------------\n",
    "    # One-hot encoder\n",
    "    # -----------------------------------------------------------------------------------------------------\n",
    "    internal_ohe = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "    columns_to_encode = [\n",
    "        \"hotel\",\n",
    "        \"meal\", \n",
    "        \"distribution_channel\", \n",
    "        \"reserved_room_type\", \n",
    "        \"assigned_room_type\", \n",
    "        \"customer_type\"\n",
    "    ]\n",
    "\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # Save the one-hot encoder columns -> MLflow\n",
    "    # --------------------------------------------\n",
    "    mlflow.log_param('ohe_columns', columns_to_encode)\n",
    "    # Get parameters from the one-hot encoder\n",
    "    encoder_params = internal_ohe.get_params()\n",
    "    # --------------------------------------------\n",
    "    # Extract and Save the one-hot encoder parameters in a dictionary -> MLflow\n",
    "    # --------------------------------------------\n",
    "    mlflow.log_params({\n",
    "        f\"encoder_{key}\": value for key, value in encoder_params.items()\n",
    "    })\n",
    "\n",
    "\n",
    "    one_hot_encoding = ColumnTransformer([\n",
    "        (\n",
    "            'one_hot_encode', internal_ohe, columns_to_encode\n",
    "        )\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "    # -----------------------------------------------------------------------------------------------------\n",
    "    # Binarizer\n",
    "    # -----------------------------------------------------------------------------------------------------\n",
    "    internal_binarizer = Binarizer()\n",
    "    columns_to_binarize = [\n",
    "        \"total_of_special_requests\", \n",
    "        \"required_car_parking_spaces\", \n",
    "        \"booking_changes\", \n",
    "        \"previous_bookings_not_canceled\", \n",
    "        \"previous_cancellations\",\n",
    "    ]\n",
    "    # primero convierte a variables dummy\n",
    "    binarizer = ColumnTransformer([\n",
    "        (\n",
    "            'binarizer', internal_binarizer, columns_to_binarize\n",
    "        )\n",
    "    ])\n",
    "    # despues aplica ohe\n",
    "    internal_encoder_binarizer = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "    one_hot_binarized = Pipeline([\n",
    "        (\"binarizer\", binarizer),\n",
    "        (\"one_hot_encoder\", internal_encoder_binarizer),\n",
    "    ])\n",
    "\n",
    "\n",
    "    # -----------------------------------------------------------------------------------------------------\n",
    "    # Scaler\n",
    "    # -----------------------------------------------------------------------------------------------------\n",
    "    internal_scaler = RobustScaler()\n",
    "    columns_to_scale = [\"adr\"]\n",
    "\n",
    "    scaler = ColumnTransformer([\n",
    "        (\"scaler\", internal_scaler, columns_to_scale)\n",
    "    ])\n",
    "\n",
    "\n",
    "    # -----------------------------------------------------------------------------------------------------\n",
    "    # Passthrough columns\n",
    "    # -----------------------------------------------------------------------------------------------------\n",
    "    pass_columns = [\n",
    "        \"stays_in_week_nights\",\n",
    "        \"stays_in_weekend_nights\",\n",
    "    ]\n",
    "\n",
    "    passthrough = ColumnTransformer([\n",
    "        (\"pass_columns\", \"passthrough\", pass_columns)\n",
    "    ])\n",
    "\n",
    "\n",
    "    # -----------------------------------------------------------------------------------------------------\n",
    "    # Full Preprocessing Pipeline\n",
    "    # -----------------------------------------------------------------------------------------------------\n",
    "    feature_engineering_pipeline  = Pipeline([\n",
    "        (\n",
    "            \"features\",\n",
    "            FeatureUnion([\n",
    "                ('categories', one_hot_encoding),\n",
    "                ('binaries', one_hot_binarized),\n",
    "                ('scaled', scaler),\n",
    "                ('passthrough', passthrough)\n",
    "            ])\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    return feature_engineering_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import set_config\n",
    "\n",
    "# preprocessing_pipeline = build_pipeline()\n",
    "# set_config(display=\"diagram\")\n",
    "# preprocessing_pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training set\n",
    "# X_train_transformed = preprocessing_pipeline.fit_transform(X_train)\n",
    "# X_train_transformed[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test set\n",
    "# X_eval_transformed = preprocessing_pipeline.transform(X_val)\n",
    "# X_eval_transformed[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test set\n",
    "# X_test_transformed = preprocessing_pipeline.transform(X_test)\n",
    "# X_test_transformed[:2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Modeling (For Multiple Algorithms)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def build_training_pipeline():\n",
    "\n",
    "    preprocessing_pipeline = build_pipeline()\n",
    "\n",
    "    # Machine learning model\n",
    "    model = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "    # -----------------------\n",
    "    # Save the parameter -> \"mlflow\"\n",
    "    # -----------------------\n",
    "    model_params = model.get_params()\n",
    "    mlflow.log_params({\n",
    "        f\"model__{key}\": value for key, value in model_params.items()\n",
    "    })\n",
    "\n",
    "\n",
    "    # Full pipeline\n",
    "    final_pipeline = Pipeline([\n",
    "        (\"feature_engineering\", preprocessing_pipeline),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    return final_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(training_pipeline, X_train, y_train):\n",
    "    # train\n",
    "    print(f\" training...!\")\n",
    "    model = training_pipeline.fit(X_train, y_train)\n",
    "    print(f\" success! \\n\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  **Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_models(models, X_true, y_true):\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    # Evaluar modelos\n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        # predict\n",
    "        y_pred = model.predict(X_true)\n",
    "        # evaluate\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "    \n",
    "        # --------------------------------\n",
    "        # Save metrics -> \"mlflow\"\n",
    "        # --------------------------------\n",
    "        mlflow.log_metrics({\n",
    "            f\"{model_name}_Accuracy\": accuracy,\n",
    "            f\"{model_name}_Precision\": precision,\n",
    "            f\"{model_name}_Recall\": recall,\n",
    "            f\"{model_name}_F1\": f1\n",
    "        })\n",
    "\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Full Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Experiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from joblib import dump\n",
    "\n",
    "def full_training_run(file_path):\n",
    "\n",
    "    # -----------------------------------\n",
    "    # set the experiment name -> \"mlflow\"\n",
    "    # -----------------------------------\n",
    "    mlflow.set_experiment(\"/turism/hotel-booking-cancellation\")\n",
    "    # start the execution block of the experiment\n",
    "    with mlflow.start_run() as run:\n",
    "\n",
    "        # load data\n",
    "        raw_dataset = load_data(file_path)\n",
    "        # split data\n",
    "        X_train, y_train, X_test, y_test, X_val, y_val = split_data(raw_dataset, 'is_canceled', train_size=0.8, val_test_proportion=0.5)\n",
    "        # build preproessing pipeline\n",
    "        training_pipeline = build_training_pipeline()\n",
    "        # training pipeline\n",
    "        model_trained_pipeline = model_train(training_pipeline, X_train, y_train)\n",
    "        # for one model\n",
    "        dict_models = {'rf_model': model_trained_pipeline,}\n",
    "        # Evaluation\n",
    "        results = eval_models(dict_models, X_val, y_val)\n",
    "\n",
    "        #dump(model_trained_pipeline, \"inference_pipeline.joblib\")\n",
    "        \n",
    "        # ----------------------------\n",
    "        # Save the model -> \"mlflow\"\n",
    "        # ----------------------------\n",
    "        # mlflow.log_artifacts(\"inference_pipeline.joblib\")\n",
    "\n",
    "        return model_trained_pipeline, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run all pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training...!\n",
      " success! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/dataset.csv\"\n",
    "trained_pipeline, results = full_training_run(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHOW RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf_model</td>\n",
       "      <td>0.813468</td>\n",
       "      <td>0.765054</td>\n",
       "      <td>0.708571</td>\n",
       "      <td>0.73573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy  Precision    Recall  F1-Score\n",
       "0  rf_model  0.813468   0.765054  0.708571   0.73573"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
